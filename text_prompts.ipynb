{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting remote sensing imagery with text prompts and the Segment Anything Model (SAM)\n",
    "\n",
    "[![image](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/opengeos/segment-geospatial/blob/main/docs/examples/text_prompts.ipynb)\n",
    "[![image](https://img.shields.io/badge/Open-Planetary%20Computer-black?style=flat&logo=microsoft)](https://pccompute.westeurope.cloudapp.azure.com/compute/hub/user-redirect/git-pull?repo=https://github.com/opengeos/segment-geospatial&urlpath=lab/tree/segment-geospatial/docs/examples/text_prompts.ipynb&branch=main)\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/segment-geospatial/blob/main/docs/examples/text_prompts.ipynb)\n",
    "\n",
    "This notebook shows how to generate object masks from text prompts with the Segment Anything Model (SAM). \n",
    "\n",
    "Make sure you use GPU runtime for this notebook. For Google Colab, go to `Runtime` -> `Change runtime type` and select `GPU` as the hardware accelerator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "Uncomment and run the following cell to install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install segment-geospatial groundingdino-py leafmap localtileserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing GroundingDINO...\n",
      "Collecting groundingdino-py\n",
      "Downloading groundingdino-py-0.4.0.tar.gz (82 kB)\n",
      "     ---------------------------------------- 82.3/82.3 kB 4.8 MB/s eta 0:00:00\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'error'\n",
      "Please restart the kernel and run the notebook again.\n"
     ]
    }
   ],
   "source": [
    "import leafmap\n",
    "from samgeo import tms_to_geotiff\n",
    "from samgeo.text_sam import LangSAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2741dc2a7a7492493bcded0b8df5a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-22.17615, -51.253043], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title'…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = leafmap.Map(center=[-22.17615, -51.253043], zoom=18, height=\"800px\")\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a sample image\n",
    "\n",
    "Pan and zoom the map to select the area of interest. Use the draw tools to draw a polygon or rectangle on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = m.user_roi_bounds()\n",
    "if bbox is None:\n",
    "    bbox = [-51.2565, -22.1777, -51.2512, -22.175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded image 01/45\n",
      "Downloaded image 02/45\n",
      "Downloaded image 03/45\n",
      "Downloaded image 04/45\n",
      "Downloaded image 05/45\n",
      "Downloaded image 06/45\n",
      "Downloaded image 07/45\n",
      "Downloaded image 08/45\n",
      "Downloaded image 09/45\n",
      "Downloaded image 10/45\n",
      "Downloaded image 11/45\n",
      "Downloaded image 12/45\n",
      "Downloaded image 13/45\n",
      "Downloaded image 14/45\n",
      "Downloaded image 15/45\n",
      "Downloaded image 16/45\n",
      "Downloaded image 17/45\n",
      "Downloaded image 18/45\n",
      "Downloaded image 19/45\n",
      "Downloaded image 20/45\n",
      "Downloaded image 21/45\n",
      "Downloaded image 22/45\n",
      "Downloaded image 23/45\n",
      "Downloaded image 24/45\n",
      "Downloaded image 25/45\n",
      "Downloaded image 26/45\n",
      "Downloaded image 27/45\n",
      "Downloaded image 28/45\n",
      "Downloaded image 29/45\n",
      "Downloaded image 30/45\n",
      "Downloaded image 31/45\n",
      "Downloaded image 32/45\n",
      "Downloaded image 33/45\n",
      "Downloaded image 34/45\n",
      "Downloaded image 35/45\n",
      "Downloaded image 36/45\n",
      "Downloaded image 37/45\n",
      "Downloaded image 38/45\n",
      "Downloaded image 39/45\n",
      "Downloaded image 40/45\n",
      "Downloaded image 41/45\n",
      "Downloaded image 42/45\n",
      "Downloaded image 43/45\n",
      "Downloaded image 44/45\n",
      "Downloaded image 45/45\n",
      "Saving GeoTIFF. Please wait...\n",
      "Image saved to Image.tif\n"
     ]
    }
   ],
   "source": [
    "image = \"Image.tif\"\n",
    "tms_to_geotiff(output=image, bbox=bbox, zoom=19, source=\"Satellite\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use your own image. Uncomment and run the following cell to use your own image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = '/path/to/your/own/image.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the downloaded image on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2741dc2a7a7492493bcded0b8df5a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-22.17615, -51.253043], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title'…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.layers[-1].visible = False\n",
    "m.add_raster(image, layer_name=\"Image\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LangSAM class\n",
    "\n",
    "The initialization of the LangSAM class might take a few minutes. The initialization downloads the model weights and sets up the model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SLConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sam \u001b[38;5;241m=\u001b[39m \u001b[43mLangSAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kainian\\Desktop\\WorkSpace\\new_project_2\\samgeo\\text_sam.py:121\u001b[0m, in \u001b[0;36mLangSAM.__init__\u001b[1;34m(self, model_type, checkpoint)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the LangSAM instance.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    model_type (str, optional): The model type. It can be one of the following: vit_h, vit_l, vit_b.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m        Defaults to 'vit_h'. See https://bit.ly/3VrpxUh for more details.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_groundingdino\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_sam(model_type, checkpoint)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kainian\\Desktop\\WorkSpace\\new_project_2\\samgeo\\text_sam.py:155\u001b[0m, in \u001b[0;36mLangSAM.build_groundingdino\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    153\u001b[0m ckpt_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroundingdino_swinb_cogcoor.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m ckpt_config_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroundingDINO_SwinB.cfg.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroundingdino \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_hf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_config_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kainian\\Desktop\\WorkSpace\\new_project_2\\samgeo\\text_sam.py:73\u001b[0m, in \u001b[0;36mload_model_hf\u001b[1;34m(repo_id, filename, ckpt_config_filename, device)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mLoads a model from HuggingFace Model Hub.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    torch.nn.Module: The loaded model.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m cache_config_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m     69\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m     70\u001b[0m     filename\u001b[38;5;241m=\u001b[39mckpt_config_filename,\n\u001b[0;32m     71\u001b[0m     force_filename\u001b[38;5;241m=\u001b[39mckpt_config_filename,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mSLConfig\u001b[49m\u001b[38;5;241m.\u001b[39mfromfile(cache_config_file)\n\u001b[0;32m     74\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(args)\n\u001b[0;32m     75\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SLConfig' is not defined"
     ]
    }
   ],
   "source": [
    "sam = LangSAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify text prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt = \"tree\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the image\n",
    "\n",
    "Part of the model prediction includes setting appropriate thresholds for object detection and text association with the detected objects. These threshold values range from 0 to 1 and are set while calling the predict method of the LangSAM class.\n",
    "\n",
    "`box_threshold`: This value is used for object detection in the image. A higher value makes the model more selective, identifying only the most confident object instances, leading to fewer overall detections. A lower value, conversely, makes the model more tolerant, leading to increased detections, including potentially less confident ones.\n",
    "\n",
    "`text_threshold`: This value is used to associate the detected objects with the provided text prompt. A higher value requires a stronger association between the object and the text prompt, leading to more precise but potentially fewer associations. A lower value allows for looser associations, which could increase the number of associations but also introduce less precise matches.\n",
    "\n",
    "Remember to test different threshold values on your specific data. The optimal threshold can vary depending on the quality and nature of your images, as well as the specificity of your text prompts. Make sure to choose a balance that suits your requirements, whether that's precision or recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.predict(image, text_prompt, box_threshold=0.24, text_threshold=0.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results\n",
    "\n",
    "Show the result with bounding boxes on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.show_anns(\n",
    "    cmap='Greens',\n",
    "    box_color='red',\n",
    "    title='Automatic Segmentation of Trees',\n",
    "    blend=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ytKMTlA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the result without bounding boxes on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.show_anns(\n",
    "    cmap='Greens',\n",
    "    add_boxes=False,\n",
    "    alpha=0.5,\n",
    "    title='Automatic Segmentation of Trees',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/3Iq2kt1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the result as a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.show_anns(\n",
    "    cmap='Greys_r',\n",
    "    add_boxes=False,\n",
    "    alpha=1,\n",
    "    title='Automatic Segmentation of Trees',\n",
    "    blend=False,\n",
    "    output='trees.tif',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/KtHwFbF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the result to a vector format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.raster_to_vector(\"trees.tif\", \"trees.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the results on the interactive map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_raster(\"trees.tif\", layer_name=\"Trees\", palette=\"Greens\", opacity=0.5, nodata=0)\n",
    "style = {\n",
    "    \"color\": \"#3388ff\",\n",
    "    \"weight\": 2,\n",
    "    \"fillColor\": \"#7c4185\",\n",
    "    \"fillOpacity\": 0.5,\n",
    "}\n",
    "m.add_vector(\"trees.shp\", layer_name=\"Vector\", style=style)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam.show_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/wydt5Xt.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
